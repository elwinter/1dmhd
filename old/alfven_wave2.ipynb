{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results from a pde1bvp_coupled_pinn.py run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import import_module\n",
    "import math as m\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the run ID (aka problem name).\n",
    "runid = \"alfven_wave2\"\n",
    "\n",
    "# Add the subdirectory for the run results to the module search path.\n",
    "run_path = os.path.join(\".\", runid)\n",
    "sys.path.append(run_path)\n",
    "\n",
    "# Import the problem definition from the run results directory.\n",
    "p = import_module(runid)\n",
    "\n",
    "# Read the run hyperparameters from the run results directory.\n",
    "import hyperparameters as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training points.\n",
    "xy_train = np.loadtxt(os.path.join(runid, \"xy_train.dat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the loss function histories.\n",
    "losses_model_in = np.loadtxt(os.path.join(runid, \"losses_model_in.dat\"))\n",
    "losses_model_bc = np.loadtxt(os.path.join(runid, \"losses_model_bc.dat\"))\n",
    "losses_model = np.loadtxt(os.path.join(runid, \"losses_model.dat\"))\n",
    "losses_in = np.loadtxt(os.path.join(runid, \"losses_in.dat\"))\n",
    "losses_bc = np.loadtxt(os.path.join(runid, \"losses_bc.dat\"))\n",
    "losses = np.loadtxt(os.path.join(runid, \"losses.dat\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model values.\n",
    "Y = []\n",
    "delY = []\n",
    "for i in range(len(p.variable_names)):\n",
    "    var_name = p.variable_names[i]\n",
    "    Y.append(np.loadtxt(os.path.join(runid, \"%s_train.dat\" % var_name)))\n",
    "    delY.append(np.loadtxt(os.path.join(runid, \"del_%s_train.dat\" % var_name)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss function histories for the individual models.\n",
    "n_models = len(p.variable_names)\n",
    "\n",
    "# Compute the number of rows for the 2-per-row plot.\n",
    "n_rows = m.ceil(n_models/2)\n",
    "\n",
    "# Plot the loss history for each model.\n",
    "plt.figure(figsize=(8, 14))\n",
    "for i in range(n_models):\n",
    "    plt.subplot(n_rows, 2, i + 1)\n",
    "    variable_name = p.variable_names[i]\n",
    "    plt.semilogy(losses_model_in[:, i], label=\"$L_{in,%s}$\" % variable_name)\n",
    "    plt.semilogy(losses_model_bc[:, i], label=\"$L_{bc,%s}$\" % variable_name)\n",
    "    plt.semilogy(losses_model[:, i], label=\"$L_{%s}$\" % variable_name)\n",
    "    plt.title(variable_name)\n",
    "    plt.legend()\n",
    "plt.suptitle(\"Loss function histories by model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the total loss function history.\n",
    "plt.semilogy(losses, label=\"$L$\")\n",
    "plt.semilogy(losses_in, label=\"$L_{in}$\")\n",
    "plt.semilogy(losses_bc, label=\"$L_{bc}$\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss function\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(\"Loss function evolution for %s\" % runid)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training points.\n",
    "xt_train = np.loadtxt(os.path.join(runid, \"xy_train.dat\"))\n",
    "x_train = xt_train[:, 0]\n",
    "t_train = xt_train[:, 1]\n",
    "\n",
    "# Create plot labels from the training points.\n",
    "x_labels = [\"%.1f\" % x for x in x_train[0:-1:hp.ny_train]]\n",
    "t_labels = [\"%.1f\" % t for t in t_train[0:hp.nx_train]]\n",
    "t_labels.reverse()\n",
    "\n",
    "# Plot the model values.\n",
    "plt.figure(figsize=(10, 20))\n",
    "for i in range(n_models):\n",
    "    plt.subplot(n_rows, 2, i + 1)\n",
    "    variable_name = p.variable_names[i]\n",
    "    # For a Seaborn heat map, reshape as (n_x, n_y), then transpose, then flip.\n",
    "    Z = np.flip(Y[i].reshape(hp.nx_train, hp.ny_train).T, axis=0)\n",
    "    ax = sns.heatmap(Z)\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"t\")\n",
    "    plt.title(variable_name)\n",
    "plt.suptitle(\"Model values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('research')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "380b67e5ff77b2374156be2418fa8d4dbbb80e970934087b3dc6e142f81df9df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
