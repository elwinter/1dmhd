{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results from a pde1bvp_coupled_pinn.py run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import import_module\n",
    "import math as m\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the run ID (aka problem name).\n",
    "runid = \"eplasma1\"\n",
    "\n",
    "# Add the subdirectory for the run results to the module search path.\n",
    "run_path = os.path.join(\".\", runid)\n",
    "sys.path.append(run_path)\n",
    "\n",
    "# Import the problem definition from the run results directory.\n",
    "p = import_module(runid)\n",
    "\n",
    "# Read the run hyperparameters from the run results directory.\n",
    "import hyperparameters as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training points.\n",
    "xy_train = np.loadtxt(os.path.join(runid, \"xy_train.dat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the loss function histories.\n",
    "losses_model_all = np.loadtxt(os.path.join(runid, \"losses_model_all.dat\"))\n",
    "losses_model_bc = np.loadtxt(os.path.join(runid, \"losses_model_bc.dat\"))\n",
    "losses_model = np.loadtxt(os.path.join(runid, \"losses_model.dat\"))\n",
    "losses_all = np.loadtxt(os.path.join(runid, \"losses_all.dat\"))\n",
    "losses_bc = np.loadtxt(os.path.join(runid, \"losses_bc.dat\"))\n",
    "losses = np.loadtxt(os.path.join(runid, \"losses.dat\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model values.\n",
    "Y = []\n",
    "delY = []\n",
    "for i in range(len(p.variable_names)):\n",
    "    var_name = p.variable_names[i]\n",
    "    Y.append(np.loadtxt(os.path.join(runid, \"%s_train.dat\" % var_name)))\n",
    "    delY.append(np.loadtxt(os.path.join(runid, \"del_%s_train.dat\" % var_name)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss function histories for the individual models.\n",
    "n_models = len(p.variable_names)\n",
    "\n",
    "# Compute the number of rows for the 2-per-row plot.\n",
    "n_rows = m.ceil(n_models/2)\n",
    "\n",
    "# Plot the loss history for each model.\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(n_models):\n",
    "    plt.subplot(n_rows, 2, i + 1)\n",
    "    variable_name = p.variable_names[i]\n",
    "    plt.semilogy(losses_model_all[:, i], label=\"$L_{all,%s}$\" % variable_name)\n",
    "    plt.semilogy(losses_model_bc[:, i], label=\"$L_{bc,%s}$\" % variable_name)\n",
    "    plt.semilogy(losses_model[:, i], label=\"$L_{%s}$\" % variable_name)\n",
    "    plt.title(variable_name)\n",
    "    plt.legend()\n",
    "plt.suptitle(\"Loss function histories by model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the total loss function history.\n",
    "plt.semilogy(losses_all, label=\"$L_{all}$\")\n",
    "plt.semilogy(losses_bc, label=\"$L_{bc}$\")\n",
    "plt.semilogy(losses, label=\"$L$\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss function\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(\"Loss function evolution for %s\" % runid)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training points.\n",
    "xt_train = np.loadtxt(os.path.join(runid, \"xy_train.dat\"))\n",
    "x_train = xt_train[:, 0]\n",
    "t_train = xt_train[:, 1]\n",
    "\n",
    "# Create plot labels from the training points.\n",
    "x_labels = [\"%.1f\" % x for x in x_train[0:-1:hp.ny_train]]\n",
    "t_labels = [\"%.1f\" % t for t in t_train[0:hp.nx_train]]\n",
    "t_labels.reverse()\n",
    "\n",
    "# Plot the model values.\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(n_models):\n",
    "    plt.subplot(n_rows, 2, i + 1)\n",
    "    variable_name = p.variable_names[i]\n",
    "    # For a Seaborn heat map, reshape as (n_x, n_y), then transpose, then flip.\n",
    "    Z = np.flip(Y[i].reshape(hp.nx_train, hp.ny_train).T, axis=0)\n",
    "    ax = sns.heatmap(Z, vmin=-0.1, vmax=0.1)\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"t\")\n",
    "    plt.title(variable_name)\n",
    "plt.suptitle(\"Model values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute wavenumber and angular frequency.\n",
    "kx =p.kx\n",
    "w = p.electron_plasma_wave_angular_frequency(p.n0, p.T, kx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute analytical solutions for n1, u1x, E1x.\n",
    "n1_a = p.n10*np.sin(kx*x_train - w*t_train)\n",
    "u1x_a = p.u1x0*np.sin(kx*x_train - w*t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the analytical solutions.\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# n1_a\n",
    "plt.subplot(1, 2, 1)\n",
    "variable_name = p.variable_names[0]\n",
    "# For a Seaborn heat map, reshape as (n_x, n_y), then transpose, then flip.\n",
    "Z = np.flip(n1_a.reshape(hp.nx_train, hp.ny_train).T, axis=0)\n",
    "ax = sns.heatmap(Z, vmin=-0.1, vmax=0.1)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"t\")\n",
    "plt.title(variable_name)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# u1x_a\n",
    "Z = np.flip(u1x_a.reshape(hp.nx_train, hp.ny_train).T, axis=0)\n",
    "ax = sns.heatmap(Z, vmin=-0.1, vmax=0.1)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"t\")\n",
    "variable_name = p.variable_names[1]\n",
    "plt.title(variable_name)\n",
    "\n",
    "plt.suptitle(\"Analytical values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the error in the predicted solutions relative to the analytical solutions.\n",
    "n1_err = Y[0] - n1_a\n",
    "u1x_err = Y[1] - u1x_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the error in the predicted solutions.\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# v1y_err\n",
    "plt.subplot(1, 2, 1)\n",
    "variable_name = p.variable_names[0]\n",
    "# For a Seaborn heat map, reshape as (n_x, n_y), then transpose, then flip.\n",
    "Z = np.flip(n1_err.reshape(hp.nx_train, hp.ny_train).T, axis=0)\n",
    "ax = sns.heatmap(Z, vmin=-0.1, vmax=0.1)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"t\")\n",
    "plt.title(variable_name)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# B1y_err\n",
    "Z = np.flip(u1x_err.reshape(hp.nx_train, hp.ny_train).T, axis=0)\n",
    "ax = sns.heatmap(Z, vmin=-0.1, vmax=0.1)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"t\")\n",
    "variable_name = p.variable_names[1]\n",
    "plt.title(variable_name)\n",
    "\n",
    "plt.suptitle(\"Prediction errors\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted, analytical, and error in n1 at t = t0 and t = t1.\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "it = 0\n",
    "x = x_train[it::hp.ny_train]\n",
    "y = Y[0][it::hp.ny_train]\n",
    "y_a = n1_a[it::hp.ny_train]\n",
    "y_err = n1_err[it::hp.ny_train]\n",
    "rms_err = np.sqrt(np.sum(y_err**2)/len(y_err))\n",
    "plt.plot(x, y, label=\"$n_{1,p}$\")\n",
    "plt.plot(x, y_a, label=\"$n_{1,a}$\")\n",
    "plt.plot(x, y_err, label=\"$n_{1,err}$\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title(\"Error in predicted $n_{1}$ at t = %f, RMS = %f\" %\n",
    "          (p.t0 + it/(hp.ny_train - 1)*(p.t1 - p.t0), rms_err))\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"$n_{1}$\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "it = hp.ny_train - 1\n",
    "x = x_train[it::hp.ny_train]\n",
    "y = Y[0][it::hp.ny_train]\n",
    "y_a = n1_a[it::hp.ny_train]\n",
    "y_err = n1_err[it::hp.ny_train]\n",
    "rms_err = np.sqrt(np.sum(y_err**2)/len(y_err))\n",
    "plt.plot(x, y, label=\"$n_{1,p}$\")\n",
    "plt.plot(x, y_a, label=\"$n_{1,a}$\")\n",
    "plt.plot(x, y_err, label=\"$n_{1,err}$\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title(\"Error in predicted $n_{1}$ at t = %f, RMS = %f\" %\n",
    "          (p.t0 + it/(hp.ny_train - 1)*(p.t1 - p.t0), rms_err))\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"$n_{1}$\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted, analytical, and error in u1x at t = t0 and t = t1.\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "it = 0\n",
    "x = x_train[it::hp.ny_train]\n",
    "y = Y[1][it::hp.ny_train]\n",
    "y_a = u1x_a[it::hp.ny_train]\n",
    "y_err = u1x_err[it::hp.ny_train]\n",
    "rms_err = np.sqrt(np.sum(y_err**2)/len(y_err))\n",
    "plt.plot(x, y, label=\"$u_{1x,p}$\")\n",
    "plt.plot(x, y_a, label=\"$u_{1x,a}$\")\n",
    "plt.plot(x, y_err, label=\"$u_{1x,err}$\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title(\"Error in predicted $u_{1x}$ at t = %f, RMS = %f\" %\n",
    "          (p.t0 + it/(hp.ny_train - 1)*(p.t1 - p.t0), rms_err))\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"$u_{1x}$\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "it = hp.ny_train - 1\n",
    "x = x_train[it::hp.ny_train]\n",
    "y = Y[1][it::hp.ny_train]\n",
    "y_a = u1x_a[it::hp.ny_train]\n",
    "y_err = u1x_err[it::hp.ny_train]\n",
    "rms_err = np.sqrt(np.sum(y_err**2)/len(y_err))\n",
    "plt.plot(x, y, label=\"$u_{1x,p}$\")\n",
    "plt.plot(x, y_a, label=\"$u_{1x,a}$\")\n",
    "plt.plot(x, y_err, label=\"$u_{1x,err}$\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title(\"Error in predicted $u_{1x}$ at t = %f, RMS = %f\" %\n",
    "          (p.t0 + it/(hp.ny_train - 1)*(p.t1 - p.t0), rms_err))\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"$u_{1x}$\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('research-3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f2da49bfea38603819e913a4c68264bf8928db0e3621ba6c2bddf34624553e02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
